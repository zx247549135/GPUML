\section{Introduction}

Many popular distributed data processing systems are sped up by in-memory computing model. Systems, such as Spark~\cite{zaharia2012resilient} and Flink~\cite{hueske2012opening}, are usually developed in Java, Scala and other managed languages. In-memory data are stored as data objects in memory, which can bloat the memory as shown in the literature~\cite{bu:bloat}. Limited memory space used by the submitted jobs will result in the memory pressure. Although these managed languages provide garbage collection(GC) to reclaim the useless data objects, caching data in memory may worsen the memory pressure as the data objects usually have a long lifetime in memory~\cite{lulu:deca}. 

Data processing systems usually work as batch processing systems. Jobs are submitted to systems individually and processed without the users' intervention. Many enterprises also deploy a data processing system as a server, such as Spark SQL~\cite{armbrust2015spark} and Hive~\cite{ashish:hive}. Multiple jobs are submitted to the system and executed in the same context. In addition to sharing the memory and CPU cores, the systems deployed as the services prefer caching the sharing data in memory in order to speed up all related jobs.
Some services are even oversold as they take the chance that all tenants may not submit their jobs at the same time. When these services process the tasks, multiple tasks are launched in the resources (such as a cluster), comparing with the original configurations where the tasks are processed by a service one by one. Data sharing and multiple launching both cause the heavy memory pressure, which in turn affects all jobs, although some jobs only cause the light memory pressure if they run alone in the batch processing mode.

%Many popular distributed systems are speed up by in-memory data in current days. These systems, such as Spark~\cite{zaharia2012resilient} and Flink~\cite{hueske2012opening}, are usually implemented by Java, Scala and other object-oriented languages. Caching data in memory is the most familiar measure for these frameworks. These caching data are stored in the JVM heap or off heap~\cite{www:tungsten} along with the runtime data objects in JVM heap. Besides the direct memory allocation for frameworks themselves, some resource managers ~\cite{vavilapalli2013apache}, distributed cache and distributed file systems~\cite{www:alluxio} also require memory to provide service for these frameworks ~\cite{pu2016fairride, li2014tachyon}. Based on the tense memory allocation, the memory pressure in frameworks themselves is already overwhelmed~\cite{fang2015interruptible}, especially when it provides service for multi tenant.

%There are two common ways, hot keys and large intermediate results, will lead to heavy memory pressure problem which harms the performance of data processing systems~\cite{fang2015interruptible}. Hot keys may result in an out-of-memory error, which may cause system crash. Large intermediate results, such as Java collection, may result in frequent garbage collection. The worst case occurs when the garbage collection time reaches a high percentage of execution time, performance of the data processing system will be extremely degraded, or system even crashes. In those systems for service, another particular problem is that some jobs have to suffer the inefficient memory pressure although they have light impact on memory. While most works mitigate memory pressure based on customized memory manager or application tuning in batch processing~\cite{www:spark-tuning, nguyen2015facade, fang2015interruptible, lulu:deca, nguyen:yak}, we intend to classify tasks those have greater impact on memory pressure in data processing systems for service. We briefly call task with greater impact on memory pressure as \textit{heavy task}, and task with light impact on memory pressure as \textit{light task}, respectively. Based on the classification, we suspend the heavy tasks to complete the light tasks, so that system resource is released and memory pressure is mitigated for all tasks.

Hot keys and large intermediate results are two common causes of the heavy memory pressure, which consequently harms the performance of data processing systems~\cite{fang2015interruptible}. Hot keys may result in an out-of-memory error, which may cause the system crash. Large intermediate results, such as Java collection, may lead to frequent garbage collection. When the garbage collection time becomes a big proportion of the entire execution time, the performance of the data processing system is significantly degraded. If the situation persists, the system may even crash. In the systems for service, another problem for the systems deployed as services is that some jobs have to suffer from the memory pressure although they cause light memory pressure themselves. Most works mitigate the memory pressure by customizing the memory managers or tuning the applications in batch processing~\cite{www:spark-tuning, nguyen2015facade, fang2015interruptible, lulu:deca, nguyen:yak}. In this work, we propose a new method to address this difficult issue. In the method, we classify the tasks in terms of memory pressure. A task that cause the heavy memory pressure is called a \textit{heavy task}, while the task with the light impact on memory called a \textit{light task}. Based on the classification, we suspend the heavy tasks so as to enable the light tasks to complete quickly. By doing so, the resources are released from running heavy tasks and the memory pressure is reduced for all tasks.

%Heavy memory pressure will break the performance of current data processing systems obviously in two common ways: hot keys and large intermediate results~\cite{fang2015interruptible}. Hot keys can result in out of memory error which can crash the system. About 40\% memory problems are related to large intermediate results, such as large Java collections. Large intermediate results can result in frequent garbage collection. The worst case is while the frequent garbage collection reclaims less space it results in the vicious circle and quickly declines the performance or even crashes systems. Systems for service cannot tolerant the heavy memory pressure much more because the heavy memory pressure may be resulted in by only parts of the running tasks. While most works mitigate the memory pressure based on the memory manger or long lived data objects in batch processing~\cite{fang2015interruptible, nguyen2015facade}, we intend to classify these tasks who have more impact on memory pressure in data processing systems for service. Based on the classification, tasks with less impact on memory pressure can break away from heavy memory pressure and release resource quickly to mitigate the memory pressure for other tasks.

%As memory pressure comes from massive long lived data objects produced by the running tasks in limited memory space, we find that the essential of long lived data objects is the function APIs called by tasks. These function APIs are based on key-value pairs~\cite{dean2008mapreduce, zaharia2012resilient, hueske2012opening, isard2007dryad} and the necessary memory space of different function APIs can be traced. The memory usage of these function APIs can be classified in four coarse-grained models: constant, sub-linear, linear, and super-linear. Each memory usage model has a different influence on memory. Task which is linear or super-linear model, or processing more input dataset, is closer to heavy task. These four models are combined independently in each task with strict order. We propose \textit{Memory Usage Rate} to determine to which model a task belongs. And we design a memory usage rate based scheduler, called MURS, which can efficiently mitigate heavy memory pressure and avoid memory overflow. The scheduler first collects the memory usage rate of current running tasks, and then selects the heavy tasks and suspend them. When heavy tasks are suspended, light tasks will complete quickly because memory pressure is light.

The memory pressure originates from massive long-living data objects produced by the running tasks in the limited memory space. Our studies further show that the root cause for generating these long-living data objects is the API functions called by the tasks. These function APIs are based on key-value pairs~\cite{dean2008mapreduce, zaharia2012resilient, hueske2012opening, isard2007dryad}. We find that the memory space used by the function APIs can be traced. The memory usage of the function APIs can be classified into four coarse-grained models: constant, sub-linear, linear and super-linear. Each memory usage model has a different influence on the memory pressure. The tasks with the linear or super-linear memory models, or the tasks that process more input dataset, are more likely to be the heavy tasks. These four models are combined independently in each task with a strict order. We propose the \textit{Memory Usage Rate} to determine which model a task belongs to. Further, we design a Memory-Usage-Rate based scheduler, called MURS, which can efficiently mitigate heavy memory pressure and avoid memory overflow. The scheduler first collects the memory usage rate of current running tasks, and then selects the heavy tasks and suspend them. After the heavy tasks are suspended, the light tasks can then complete quickly because of the light memory pressure. 

%As the memory pressure is coming from the massive long lived data object produced by the running tasks, tasks from different tenant will have different impact on memory pressure. Current data processing systems provide their own function APIs for user programs, and each task executes several function APIs~\cite{dean2008mapreduce, zaharia2012resilient, hueske2012opening, isard2007dryad}. We find that these function APIs are based on K-V pairs and the necessary memory space of different function APIs can be traced. The memory usage of these function APIs can be traced by four coarse-grained models: constant, sub-linear, linear and super-linear. Each model has different influence on memory, which means it can produce different memory pressure. Constant and sub-linear models have lighter effect on the memory pressure than linear model or super-linear model. These models are grouped independently in each task. We propose \textit{Memory Usage Rate} to distinguish which model one task belongs to. And we design a memory usage rate based scheduler called MURS which is proved to can avoid heavy memory pressure and spill. The scheduler gets the memory usage rate of current running tasks firstly, and chooses these tasks with linear or super-linear model to stop. When tasks with heavy influence on memory pressure is stopped, other tasks can complete quickly because memory pressure is light.

%Most works propose methods to slow down the memory pressure in batch processing, such as region based memory management~\cite{nguyen2015facade, gog2015broom}. However, the problem in multi-tenant is not always suited for these measures. Tenants who need less execution memory should not suffer heavy memory pressure poduced by other tenants. On the contrary, tenants who produce heavy memory pressure cannot get the resources of others immediately because others are prevented to complete early. The root of memory pressure is the running tasks who produce massive data objects in memory. Considering all tasks with the same characters is not appropriate in multi-tenant.

%Further more, users in both batch processing and multi-tenant write their codes by specific function APIs provided by frameworks, and then submit their jobs to system. As submitted job is always split into a set of tasks, each task executes several function APIs. Tasks running in the same time execute the same function APIs in batch processing but different function APIs in multi-tenant. Tasks with different function APIs have diverse effect on memory pressure undisputed, we find that although these tasks implement with the same function APIs, they can also have diverse effect on memory pressure because the distribution of keys in dataset also effect the memory pressure in some way. Thus, a uniform criterion to mark the influence on memory pressure of different tasks is most helpful to mange the tasks for both batch processing and multi-tenant.

%// 重点改



%In this paper, we analyze the characters of common function APIs in current popular data processing systems firstly. We propose \textit{Memory Usage Rate} to measure the influence one task has on the memory pressure. Four coarse grained types are designed to stand for different characters: constant, sub-linear, linear and super-linear. Constant tasks and sub-linear tasks have lighter effect on the memory pressure than linear tasks or super-leaner tasks. Based on the memory usage rate of current running tasks, we design a scheduler called MURS to schedule the tasks and avoid heavy memory pressure. The scheduler gets the memory usage rate of current running tasks in time and proposes the super linear or linear tasks to stop when the memory pressure comes. These stopped tasks will prevent heavy memory pressure because the heavy memory pressure is resulted in by themselves. Other tasks can run more quickly to empty the memory space for the stopped tasks.

%Last but not the least, we provide multi-launch to efficiently use memory. When light tasks have a large proportion in the running tasks, memory pressure is not heavy. Multi-launch will launch more tasks than original configuration to increase the parallelism as well as the memory pressure. In MURS, high parallelism can speed up the execution without considering heavy memory pressure. The multi-launch can be shut down optionally when the CPU resource is limited.

%Last but not the least, stopping tasks of some jobs is not appropriate in some way. Thus we provide multi launch to balance the stop, which can 1) speed up the occur of memory pressure and the response time for all submitted jobs; 2) increase the memory usage when all tasks have light pressure on memory by increasing parallelism. High parallelism instead of more memory pressure can improve the performance in some way. 

We implement MURS in Spark and conduct the extensive experiments. The experiments results shows that the execution time can be reduced by up to 65.8\% (2.9X). The garbage collection, which directly measures the memory pressure, can decrease by a maximum of 81\%. MURS can also help improve the scalability of the system, as the system equipped with MURS can still provide high quality of service even if the memory is in shortage. 

In summary, this work offers the following three main contributions.

\begin{itemize}

\item We analyze the memory utilization of various data processing systems, and find that the memory pressure originates from the function APIs called by the data processing frameworks when running the tasks. The invocation of the API functions generate massive long living data objects, which consume a large amount of memory.
%\item We propose memory usage rate which is bound to each task as a unified criterion for distinguishing their memory usage models in data processing systems for service. The criterion can extend to most data processing systems.

\item Based on our findings, we build four memory usage models to measure the impact a task has on memory pressure. The proposed models are independent of the data processing systems (and their function APIs). We also propose to use memory usage rate to identify which model a task belongs to. We design the memory usage rate based scheduler called MURS, which releases the memory pressure substantially.

%\item We propose multi launch to speed up the advent of memory pressure and increase the parallelism. The balance of pressure and parallelism can also improve the performance in some sense.

\item We implement a prototype system of MURS based on Spark. The proposed method can be ported to other similar data processing systems. The experimental results have shown that our system can significantly improve system performance, reduce garbage collection and extend the scalability of server.

\end{itemize}

The rest of the paper is organized as follows. Section II introduces the motivation of our work. Section III describes the four types of memory usage rate. Section IV characterizes the scheduler with the tasks with different memory usage rates. Section V presents the implementation of MURS; Performance evaluation is carried out in Section VI to show the advantages of our scheduler. In Section VII, we discuss the related work. Finally, Section VIII concludes the paper.