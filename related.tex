\section{Related Work}

Memory pressure has been studied several years in different ways, such as tuning of garbage collection, memory management and task scheduler. Most of these works focus on the offline calculation in data processing systems. 

\textbf{Garbage Collection} Most garbage collection tuning are based on the features of the applications, such as Spark applications~\cite{www:spark-tuning}, Cassandra applications~\cite{www:cassandra}. And the measures have two points: 1) replace other garbage collection algorithms, such as Concurrent Mark Sweep (CMS) or Garbage First (G1); 2) tune important parameters, such as the ratio of young generation and old generation, to avoid frequent GC activity and data copy. Most researches attempt to rebuild the algorithm of garbage collection to apply for common applications. For example, Yang et al.\cite{yang:fullgc} describes an incremental query model for reference calculation to optimize the cause of full GC. This garbage collection algorithm can be universal relevance to most memory pressure. Rodrigo et al.\cite{rodigo:NGeneration} proposed N-Generational garbage collector for big data memory management which also reduce the data copy in garbage collection. Garbage collection tuning always need proficient technology on the data processing systems and the problem is potential existed.

\textbf{Memory Management} The memory analysis of data-intensive big data applications are put forward clearly by Bu et al.~\cite{bu:bloat}. They consider the bloat of memory in object-oriented languages and design the bloat-aware paradigm: 1) merging small data to big data; 2) manipulating data directly accessing the buffers. Some memory management at the system level also extend the language-level optimization, such as region based memory management (RBMM)~\cite{nguyen2015facade, nguyen:yak} and lifetime based memory management~\cite{lulu:deca}. Nguyen et al.~\cite{nguyen2015facade} advice users to mark the class information in applications to decompose data object to regions, then memory can be allocated or reclaimed by regions. Based on the same theory, they also proposed a new garbage collector to mange data objects and control objects separately to extend the method to iterative computations~\cite{nguyen:yak}. Lu et al.~\cite{lulu:deca} propose the lifetime based memory management, they decompose data objects based on the data container which decides the lifetime of data objects. The decomposed data objects will have less pressure on the memory and can be allocated and reclaimed by regions. Memory management provides professional and effective way for memory pressure with a great quantity of work.

\textbf{Task Scheduler} As memory pressure is produced by the running task, task scheduler can also release the memory pressure or improve the efficiency of memory. Fang et al.~\cite{fang2015interruptible} design interruptible tasks for data-parallel programs. They clear the memory consumption of one task to four parts: local data structures, processed input, unprocessed input and result. Based on their novel programming model, interruptible tasks can release parts of the memory consumption of random tasks when memory pressure comes, and be resumed when memory pressure decreases. Interruptible tasks can be resumed with the remained in-memory data. Pu et al.~\cite{pu2016fairride} implement a new policy called FairRide to fair allocate memory cache for multiple users with shared files through efficiently blocking. This efficient policy first satisfies both three desirable properties: isolation-guarantee, strategy-proofness and Pareto-efficiency. Based on different scheduling standard, task scheduler always adapts different demand and is convenient to be implemented.
